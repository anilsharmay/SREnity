{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer LangGraph Log Analysis\n",
    "\n",
    "This notebook provides an interactive interface for running multi-layer log analysis using LangGraph.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- **Layer 1: Router** - Routes log files directly to their corresponding tools (no keyword searching needed)\n",
    "- **Layer 2: Tool Nodes** - web_tool, app_tool, db_tool (separate nodes)\n",
    "- **Layer 3: Aggregator** - Collects all tool results\n",
    "- **Layer 4: Summarizer** - Creates final comprehensive summary\n",
    "\n",
    "## Direct File Routing\n",
    "\n",
    "- `web.log` → `web_tool`\n",
    "- `app.log` → `app_tool`\n",
    "- `db.log` → `db_tool`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend directory: c:\\Users\\Chandu\\Documents\\AIOps_Solution\\backend\n",
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set OpenAI API key if not already set\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    import getpass\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "# Read path from config\n",
    "from config import BACKEND_DIR\n",
    "\n",
    "# Add backend parent to Python path\n",
    "backend_parent = BACKEND_DIR.parent\n",
    "if str(backend_parent) not in sys.path:\n",
    "    sys.path.insert(0, str(backend_parent))\n",
    "\n",
    "print(f\"Backend directory: {BACKEND_DIR}\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from backend.analysis.tools import create_web_rag_tool, create_app_rag_tool, create_db_rag_tool\n",
    "from backend.analysis.graph import (\n",
    "    create_router_node,\n",
    "    create_web_tool_node,\n",
    "    create_app_tool_node,\n",
    "    create_db_tool_node,\n",
    "    create_aggregator_node,\n",
    "    create_summarizer_node,\n",
    "    build_multi_layer_graph,\n",
    "    MultiLayerState\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Log Files Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logs(scenario=\"scenario1_web_issue\"):\n",
    "    \"\"\"\n",
    "    Load log files separately from logs directory.\n",
    "    Returns a dictionary with separate log contents - NOT joined/combined.\n",
    "    Each log file stays separate: web.log, app.log, db.log\n",
    "    \n",
    "    Args:\n",
    "        scenario: Scenario directory name (default: \"scenario1_web_issue\")\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'web', 'app', 'db' containing log file contents\n",
    "    \"\"\"\n",
    "    # Read path from config\n",
    "    from config import LOGS_DIR\n",
    "    \n",
    "    # Logs are in backend/data/logs/scenario/\n",
    "    logs_dir = LOGS_DIR / scenario\n",
    "    \n",
    "    if not logs_dir.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Logs directory not found: {logs_dir}\\n\"\n",
    "            f\"Available scenarios: {list(LOGS_DIR.iterdir()) if LOGS_DIR.exists() else 'No logs directory found'}\"\n",
    "        )\n",
    "    \n",
    "    # Load each log file separately - keep them separate, don't combine\n",
    "    logs = {}\n",
    "    for tier in [\"web\", \"app\", \"db\"]:\n",
    "        path = logs_dir / f\"{tier}.log\"\n",
    "        if path.exists():\n",
    "            with open(path, encoding=\"utf-8\") as f:\n",
    "                logs[tier] = f.read()\n",
    "        else:\n",
    "            logs[tier] = \"\"\n",
    "            print(f\"Warning: {path} not found\")\n",
    "    \n",
    "    return logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize System\n",
    "\n",
    "### Step 1: System Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multi-Layer LangGraph System...\n",
      "================================================================================\n",
      "Layer 1: Router - Decides which tools to use\n",
      "Layer 2: Tool Nodes - web_tool, app_tool, db_tool (separate nodes)\n",
      "Layer 3: Aggregator - Collects all tool results\n",
      "Layer 4: Summarizer - Creates final summary\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Multi-Layer LangGraph System...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Layer 1: Router - Decides which tools to use\")\n",
    "print(\"Layer 2: Tool Nodes - web_tool, app_tool, db_tool (separate nodes)\")\n",
    "print(\"Layer 3: Aggregator - Collects all tool results\")\n",
    "print(\"Layer 4: Summarizer - Creates final summary\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize LLM and Create RAG Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating RAG tools...\n",
      "All RAG tools created\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create RAG tools\n",
    "print(\"\\nCreating RAG tools...\")\n",
    "web_rag_tool = create_web_rag_tool()\n",
    "app_rag_tool = create_app_rag_tool()\n",
    "db_rag_tool = create_db_rag_tool()\n",
    "print(\"All RAG tools created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Graph Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating graph nodes...\n",
      "  Router node created\n",
      "  Tool nodes created (web, app, db)\n",
      "  Aggregator node created\n",
      "  Summarizer node created\n"
     ]
    }
   ],
   "source": [
    "# Create nodes for each layer\n",
    "print(\"\\nCreating graph nodes...\")\n",
    "\n",
    "# Layer 1: Router (no LLM needed - simple routing logic)\n",
    "router_node = create_router_node()\n",
    "print(\"  Router node created\")\n",
    "\n",
    "# Layer 2: Tool nodes\n",
    "web_tool_node = create_web_tool_node(web_rag_tool)\n",
    "app_tool_node = create_app_tool_node(app_rag_tool)\n",
    "db_tool_node = create_db_tool_node(db_rag_tool)\n",
    "print(\"  Tool nodes created (web, app, db)\")\n",
    "\n",
    "# Layer 3: Aggregator\n",
    "aggregator_node = create_aggregator_node()\n",
    "print(\"  Aggregator node created\")\n",
    "\n",
    "# Layer 4: Summarizer\n",
    "summarizer_node = create_summarizer_node(llm)\n",
    "print(\"  Summarizer node created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build the Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building multi-layer graph...\n",
      "Graph built successfully\n"
     ]
    }
   ],
   "source": [
    "# Build graph\n",
    "print(\"\\nBuilding multi-layer graph...\")\n",
    "compiled_graph = build_multi_layer_graph(\n",
    "    router_node,\n",
    "    web_tool_node,\n",
    "    app_tool_node,\n",
    "    db_tool_node,\n",
    "    aggregator_node,\n",
    "    summarizer_node\n",
    ")\n",
    "print(\"Graph built successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Log Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading logs...\n",
      "Loaded logs: Web=2598 chars, App=1898 chars, DB=1651 chars\n"
     ]
    }
   ],
   "source": [
    "# Load logs separately - no need to combine\n",
    "print(\"\\nLoading logs...\")\n",
    "logs = load_logs()  # Change scenario name if needed: load_logs(\"scenario2_app_issue\")\n",
    "\n",
    "# Keep logs separate - web.log to web_tool, app.log to app_tool, db.log to db_tool\n",
    "web_log = logs.get(\"web\", \"\")\n",
    "app_log = logs.get(\"app\", \"\")\n",
    "db_log = logs.get(\"db\", \"\")\n",
    "\n",
    "total_chars = len(web_log) + len(app_log) + len(db_log)\n",
    "if total_chars == 0:\n",
    "    print(\"Warning: No logs found.\")\n",
    "else:\n",
    "    print(f\"Loaded logs: Web={len(web_log)} chars, App={len(app_log)} chars, DB={len(db_log)} chars\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Initial State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state created with separate log files\n"
     ]
    }
   ],
   "source": [
    "# Create initial state with separate log files\n",
    "initial_state: MultiLayerState = {\n",
    "    \"messages\": [HumanMessage(content=\"Analyzing system logs from web, app, and db tiers\")],\n",
    "    \"web_log\": web_log,      # web.log goes directly to web_tool\n",
    "    \"app_log\": app_log,      # app.log goes directly to app_tool\n",
    "    \"db_log\": db_log,        # db.log goes directly to db_tool\n",
    "    \"web_result\": \"\",\n",
    "    \"app_result\": \"\",\n",
    "    \"db_result\": \"\",\n",
    "    \"next\": \"\",\n",
    "    \"tool_results\": {}\n",
    "}\n",
    "\n",
    "print(\"Initial state created with separate log files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "\n",
    "### Stream Execution (See Each Layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running multi-layer analysis...\n",
      "================================================================================\n",
      "\n",
      "[Layer: router]\n",
      "  Next: web_tool\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: web_tool]\n",
      "Web Tier Analysis:\n",
      "The logs analyzed contain multiple ERROR entries indicating issues with the web tier. Here’s a summary of the findings:\n",
      "\n",
      "### 1. **Error Detection:**\n",
      "- The logs include multiple entries with [ERROR] markers, alongside server responses indicating **502 Bad Gateway**, **504 Gateway T...\n",
      "  Next: router\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: router]\n",
      "  Next: app_tool\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: app_tool]\n",
      "App Tier Analysis:\n",
      "The provided logs primarily consist of [INFO] level messages that indicate successful operations of various services. There are no [ERROR] or [WARN] messages present.\n",
      "\n",
      "### Analysis of Logs:\n",
      "- All entries in the logs are at the INFO level.\n",
      "- Each log entry indicates a successful re...\n",
      "  Next: router\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: router]\n",
      "  Next: db_tool\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: db_tool]\n",
      "DB Tier Analysis:\n",
      "**Log Analysis Results:**\n",
      "\n",
      "**Status:** Healthy  \n",
      "**Severity:** None/Low  \n",
      "**Summary:** All operations logged between 2024-01-15T14:30:01.156Z and 2024-01-15T14:30:10.453Z are successful, indicating normal database operation with no errors reported. Notable entries include multiple ...\n",
      "  Next: router\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: router]\n",
      "  Next: aggregate\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Layer: aggregate]\n",
      "Aggregated Results:\n",
      "=== WEB TIER ===\n",
      "The logs analyzed contain multiple ERROR entries indicating issues with the web tier. Here’s a summary of the findings:\n",
      "\n",
      "### 1. **Error Detection:**\n",
      "- The logs include multiple entries with [ERROR] markers, alongside server responses indicating **502 Bad Gateway*...\n",
      "  Next: summarizer\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check if compiled_graph exists\n",
    "if 'compiled_graph' not in globals():\n",
    "    raise NameError(\n",
    "        \"compiled_graph is not defined. \"\n",
    "        \"Please run the 'Build the Graph' cell (Step 4) first to create compiled_graph.\"\n",
    "    )\n",
    "\n",
    "# Run the graph\n",
    "print(\"\\nRunning multi-layer analysis...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # Stream results to see each layer\n",
    "    for step in compiled_graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
    "        for node_name, node_output in step.items():\n",
    "            if node_name != \"__end__\":\n",
    "                print(f\"\\n[Layer: {node_name}]\")\n",
    "                if \"messages\" in node_output and node_output[\"messages\"]:\n",
    "                    last_msg = node_output[\"messages\"][-1]\n",
    "                    if hasattr(last_msg, \"content\"):\n",
    "                        content = str(last_msg.content)\n",
    "                        # Show first 300 chars\n",
    "                        preview = content[:300] + \"...\" if len(content) > 300 else content\n",
    "                        print(preview)\n",
    "                if \"next\" in node_output:\n",
    "                    print(f\"  Next: {node_output['next']}\")\n",
    "                print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Error during streaming: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Complete!\n",
      "================================================================================\n",
      "\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "# FINAL INCIDENT SUMMARY\n",
      "\n",
      "### Final Incident Summary\n",
      "\n",
      "#### 1. Executive Summary\n",
      "On January 15, 2024, a series of issues were identified within the web tier, leading to significant HTTP errors including `502 Bad Gateway`, `503 Service Unavailable`, and `504 Gateway Timeout`. The application tier and database tier, however, remained healthy throughout the incident, demonstrating stability and efficiency in their operations. This incident underscores the importance of ensuring robust communication and performance monitoring between the web and upstream services.\n",
      "\n",
      "#### 2. Tier Analysis\n",
      "- **Web Tier**:\n",
      "  - **Status**: Unhealthy\n",
      "  - **Errors**: Frequent `502`, `503`, and `504` errors indicating upstream service communication failures and server overload.\n",
      "  - **Severity**: High\n",
      "  - **Key Findings**: The web tier is compromised due to upstream server responsiveness issues and potential overload. Immediate investigation into backend service health is required.\n",
      "\n",
      "- **App Tier**:\n",
      "  - **Status**: Healthy\n",
      "  - **Severity**: None\n",
      "  - **Key Findings**: The application logged only successful operations, with average processing times well within expected norms (43ms). This tier is confirmed operational and efficient.\n",
      "\n",
      "- **DB Tier**:\n",
      "  - **Status**: Healthy\n",
      "  - **Severity**: None\n",
      "  - **Key Findings**: All database queries executed successfully within an average of 19ms. No performance issues or errors were detected.\n",
      "\n",
      "#### 3. Cross-Tier Correlations\n",
      "The web tier's issues directly correlate with upstream service outages affecting the application tier. While the application tier processes requests successfully without any errors, the web tier's inability to communicate with it effectively results in failed client requests. The database tier’s performance remains unaffected by the events impacting the other tiers, indicating it operates independently without contributing to the web tier's issues.\n",
      "\n",
      "#### 4. Root Cause Analysis\n",
      "The root cause of the incident is twofold: \n",
      "1. **Upstream Service Availability**: The upstream servers are either down or delayed, preventing the web tier from processing requests correctly.\n",
      "2. **Web Server Misconfiguration**: The existing timeout settings in Apache are inadequately configured for current loads, contributing to premature timeout errors.\n",
      "\n",
      "#### 5. Impact Assessment\n",
      "The impact of this incident on users was significant, leading to unresponsive web services, with a direct correlation to client dissatisfaction and a potential loss of revenue due to inaccessible services. While there were no issues in the application and database tiers, the cascading failures from the web tier affected overall service availability.\n",
      "\n",
      "#### 6. Remediation Plan\n",
      "1. **Immediate Actions**:\n",
      "   - Diagnose and restore health of upstream servers to ensure availability.\n",
      "   - Increase timeout configurations in Apache to mitigate premature timeouts.\n",
      "   - Monitor server load and query performance actively to alleviate overload.\n",
      "\n",
      "2. **Short-term Actions**:\n",
      "   - Scale resources (e.g., horizontal scaling of servers) to handle increased traffic.\n",
      "   - Perform stress testing after adjustments to validate stability under load.\n",
      "\n",
      "#### 7. Prevention Recommendations\n",
      "1. **Monitoring**: Implement robust health checks and performance monitoring for upstream services and the web tier to facilitate early detection of connectivity issues.\n",
      "2. **Configuration Reviews**: Regularly review timeout settings based on the latest performance metrics and load scenarios.\n",
      "3. **Rate Limiting**: Introduce rate limiting for incoming requests to manage traffic spikes and prevent server saturation.\n",
      "4. **Regular Load Testing**: Conduct consistent load testing to proactively identify configuration needs and adjust resources accordingly.\n",
      "\n",
      "By addressing the identified areas and implementing the remediation and prevention strategies, we can significantly enhance our observability and resilience to future incidents.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get final result\n",
    "    final_result = compiled_graph.invoke(initial_state, {\"recursion_limit\": 20})\n",
    "    \n",
    "    print(\"\\nAnalysis Complete!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Print final summary\n",
    "    if \"messages\" in final_result:\n",
    "        print(\"\\nFINAL SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        for msg in final_result[\"messages\"]:\n",
    "            if hasattr(msg, \"name\") and msg.name == \"summarizer\":\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    print(msg.content)\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"Error during analysis: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Individual Tool Results\n",
    "\n",
    "You can also inspect individual tool results from the final state:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to view individual results:\n",
    "#print(\"\\nWeb Tier Results:\")\n",
    "#print(final_result.get(\"web_result\", \"No results\"))\n",
    "#print(\"\\nApp Tier Results:\")\n",
    "#print(final_result.get(\"app_result\", \"No results\"))\n",
    "#print(\"\\nDB Tier Results:\")\n",
    "#print(final_result.get(\"db_result\", \"No results\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Structure (Mermaid Diagram):\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compiled_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph Structure (Mermaid Diagram):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m mermaid_diagram \u001b[38;5;241m=\u001b[39m compiled_graph\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mdraw_mermaid()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(mermaid_diagram)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save to file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compiled_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize Graph Structure (Mermaid Diagram)\n",
    "print(\"Graph Structure (Mermaid Diagram):\")\n",
    "print(\"=\" * 80)\n",
    "mermaid_diagram = compiled_graph.get_graph().draw_mermaid()\n",
    "print(mermaid_diagram)\n",
    "\n",
    "# Save to file\n",
    "with open(\"graph_structure.mmd\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(mermaid_diagram)\n",
    "print(\"\\nGraph saved to graph_structure.mmd\")\n",
    "print(\"You can view it at: https://mermaid.live/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SREnity)",
   "language": "python",
   "name": "srenity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}