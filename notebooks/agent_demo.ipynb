{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SREnity Agent Demo - LangGraph ReAct Implementation\n",
        "\n",
        "This notebook demonstrates the agentic RAG system using LangGraph with a 2-node ReAct pattern:\n",
        "- **Assistant Node**: Agent reasoning and tool selection\n",
        "- **Tool Node**: Execute search_runbooks and search_web tools\n",
        "\n",
        "## Features:\n",
        "- Intelligent tool selection based on query analysis\n",
        "- Guardrails to refuse off-topic queries\n",
        "- Fallback from runbooks to web search when needed\n",
        "- Clear agent reasoning visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import os\n",
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# Tavily search\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Local imports\n",
        "from src.utils.config import get_config, get_model_factory\n",
        "from src.rag.advanced_retrieval import create_bm25_reranker_chain\n",
        "from src.utils.document_loading import load_and_chunk_documents\n",
        "\n",
        "print(\"‚úÖ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Graph State\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphState(TypedDict):\n",
        "    \"\"\"State for the agent graph\"\"\"\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "\n",
        "print(\"‚úÖ GraphState defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Existing RAG Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "config = get_config()\n",
        "model_factory = get_model_factory()\n",
        "\n",
        "# Load and chunk documents (reuse from rag_evaluation)\n",
        "print(\"Loading documents...\")\n",
        "chunked_docs = load_and_chunk_documents()\n",
        "print(f\"‚úÖ Loaded {len(chunked_docs)} document chunks\")\n",
        "\n",
        "# Create BM25 + Reranker chain for runbook search\n",
        "print(\"Creating BM25 + Reranker chain...\")\n",
        "bm25_reranker_chain = create_bm25_reranker_chain(chunked_docs, model_factory, bm25_k=12, rerank_k=5)\n",
        "print(\"‚úÖ BM25 + Reranker chain ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_runbooks(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search GitLab SRE runbooks for troubleshooting procedures, commands, and best practices.\n",
        "    \n",
        "    Use this tool for:\n",
        "    - Standard SRE procedures\n",
        "    - Troubleshooting steps\n",
        "    - Command syntax and usage\n",
        "    - Infrastructure best practices\n",
        "    \n",
        "    Args:\n",
        "        query: The SRE question or issue to search for\n",
        "    \n",
        "    Returns:\n",
        "        Formatted response with runbook guidance\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = bm25_reranker_chain.invoke({\"question\": query})\n",
        "        return result[\"response\"]\n",
        "    except Exception as e:\n",
        "        return f\"Error searching runbooks: {str(e)}\"\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search the web for latest updates, CVEs, version-specific issues, and recent changes.\n",
        "    \n",
        "    Use this tool for:\n",
        "    - Recent vulnerabilities or security updates\n",
        "    - Version-specific issues not in runbooks\n",
        "    - Latest best practices or changes\n",
        "    - Breaking changes in tools or services\n",
        "    \n",
        "    Args:\n",
        "        query: The technical question to search for on the web\n",
        "    \n",
        "    Returns:\n",
        "        Recent web information and updates\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize Tavily search\n",
        "        tavily_tool = TavilySearchResults(\n",
        "            max_results=3,\n",
        "            search_depth=\"advanced\"\n",
        "        )\n",
        "        \n",
        "        # Search with SRE context\n",
        "        search_query = f\"SRE DevOps {query} troubleshooting production incident\"\n",
        "        results = tavily_tool.invoke(search_query)\n",
        "        \n",
        "        # Format results\n",
        "        if results:\n",
        "            formatted_results = \"\\n\\n\".join([\n",
        "                f\"**Source:** {result.get('title', 'Unknown')}\\n\"\n",
        "                f\"**URL:** {result.get('url', 'N/A')}\\n\"\n",
        "                f\"**Content:** {result.get('content', 'No content available')}\"\n",
        "                for result in results\n",
        "            ])\n",
        "            return f\"Recent web information:\\n\\n{formatted_results}\"\n",
        "        else:\n",
        "            return \"No recent web information found for this query.\"\n",
        "            \n",
        "    except Exception as e:\n",
        "        return f\"Error searching web: {str(e)}\"\n",
        "\n",
        "# Create tools list\n",
        "tools = [search_runbooks, search_web]\n",
        "print(f\"‚úÖ Created {len(tools)} tools:\")\n",
        "for tool in tools:\n",
        "    print(f\"  - {tool.name}: {tool.description}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create LLM with Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LLM with tools\n",
        "llm = model_factory.get_llm()\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "print(\"‚úÖ LLM configured with tools\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Agent Nodes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assistant(state: GraphState):\n",
        "    \"\"\"\n",
        "    Assistant node: Agent reasoning and tool selection\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    \n",
        "    # Add system message if this is the first message\n",
        "    if len(messages) == 1 and isinstance(messages[0], HumanMessage):\n",
        "        system_message = \"\"\"\n",
        "You are SREnity, an expert SRE (Site Reliability Engineer) assistant specialized in production incident response.\n",
        "\n",
        "Your expertise includes:\n",
        "- Infrastructure troubleshooting (Redis, PostgreSQL, Elastic, etc.)\n",
        "- GitLab runbook procedures\n",
        "- Production incident resolution\n",
        "- DevOps best practices\n",
        "\n",
        "TOOL USAGE RULES:\n",
        "1. ALWAYS start with search_runbooks for SRE procedures and troubleshooting\n",
        "2. Use search_web ONLY when:\n",
        "   - Runbooks don't have the specific information needed\n",
        "   - You need latest updates, CVEs, or version-specific issues\n",
        "   - The query involves recent changes or breaking updates\n",
        "3. REFUSE non-SRE queries politely but firmly\n",
        "\n",
        "GUARDRAILS:\n",
        "- If the query is clearly off-topic (weather, cooking, general knowledge, personal advice), respond:\n",
        "  \"I'm specialized in SRE incident response and can only help with infrastructure troubleshooting, runbook procedures, and production issues. Please ask about system operations or technical problems.\"\n",
        "- Do NOT use tools for off-topic queries\n",
        "\n",
        "Always provide clear, actionable guidance based on the information you find.\n",
        "\"\"\"\n",
        "        messages = [AIMessage(content=system_message)] + messages\n",
        "    \n",
        "    # Get response from LLM\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    \n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def should_continue(state: GraphState):\n",
        "    \"\"\"\n",
        "    Conditional edge: Determine if tools need to be called\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    # If the last message has tool calls, go to tools\n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    \n",
        "    # Otherwise, we're done\n",
        "    return END\n",
        "\n",
        "# Create tool node\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "print(\"‚úÖ Agent nodes defined:\")\n",
        "print(\"  - assistant: Agent reasoning and tool selection\")\n",
        "print(\"  - should_continue: Conditional edge logic\")\n",
        "print(\"  - tool_node: Tool execution\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Build and Compile Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the graph\n",
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Set entry point\n",
        "builder.add_edge(START, \"assistant\")\n",
        "\n",
        "# Add conditional edge\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    should_continue,\n",
        "    {\"tools\": \"tools\", END: END}\n",
        ")\n",
        "\n",
        "# Add edge from tools back to assistant\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "\n",
        "# Compile the graph\n",
        "react_graph = builder.compile()\n",
        "\n",
        "print(\"‚úÖ ReAct graph compiled successfully!\")\n",
        "print(\"\\nGraph structure:\")\n",
        "print(\"START ‚Üí assistant ‚Üí [tools or END]\")\n",
        "print(\"              ‚Üë          ‚Üì\")\n",
        "print(\"              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Agent with Sample Queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_agent(query: str, verbose: bool = True):\n",
        "    \"\"\"\n",
        "    Test the agent with a query and show the reasoning process\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"QUERY: {query}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create initial state\n",
        "    initial_state = {\"messages\": [HumanMessage(content=query)]}\n",
        "    \n",
        "    # Run the graph\n",
        "    if verbose:\n",
        "        print(\"\\nü§ñ Agent reasoning process:\")\n",
        "        \n",
        "    result = react_graph.invoke(initial_state, config={\"recursion_limit\": 10})\n",
        "    \n",
        "    # Extract final response\n",
        "    final_message = result[\"messages\"][-1]\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"\\nüìù Final Response:\")\n",
        "        print(\"-\" * 40)\n",
        "    \n",
        "    print(final_message.content)\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"‚úÖ Test function ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Demo Scenarios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: Standard SRE query (should use runbooks only)\n",
        "test_agent(\"How to monitor Redis memory usage?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 2: Version-specific query (should use both tools)\n",
        "test_agent(\"Redis 7.2 memory leak issues and fixes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 3: Off-topic query (should refuse)\n",
        "test_agent(\"What's the weather like today?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 4: Complex SRE query (should use both tools)\n",
        "test_agent(\"PostgreSQL connection pool exhaustion in production - how to diagnose and fix?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 5: Command-specific query (should use runbooks)\n",
        "test_agent(\"Show me the exact syntax for Redis MEMORY STATS command\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interactive Demo\n",
        "\n",
        "Run this cell to interact with the agent:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive demo\n",
        "def interactive_demo():\n",
        "    \"\"\"\n",
        "    Interactive demo of the SREnity agent\n",
        "    \"\"\"\n",
        "    print(\"ü§ñ SREnity Agent Demo\")\n",
        "    print(\"Ask me about SRE procedures, troubleshooting, or production issues!\")\n",
        "    print(\"Type 'quit' to exit.\\n\")\n",
        "    \n",
        "    while True:\n",
        "        query = input(\"You: \")\n",
        "        \n",
        "        if query.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"Goodbye! üëã\")\n",
        "            break\n",
        "            \n",
        "        if query.strip():\n",
        "            test_agent(query, verbose=False)\n",
        "            print()\n",
        "\n",
        "# Uncomment to run interactive demo\n",
        "# interactive_demo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Graph Visualization\n",
        "\n",
        "Visualize the agent graph structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the graph structure\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    \n",
        "    # Generate graph image\n",
        "    graph_image = react_graph.get_graph().draw_mermaid()\n",
        "    \n",
        "    print(\"üìä Agent Graph Structure:\")\n",
        "    print(\"\\nMermaid representation:\")\n",
        "    print(graph_image)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Could not generate graph visualization: {e}\")\n",
        "    print(\"\\nGraph structure:\")\n",
        "    print(\"START ‚Üí assistant ‚Üí [tools or END]\")\n",
        "    print(\"              ‚Üë          ‚Üì\")\n",
        "    print(\"              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
